services:
  # Postgres Database
  postgres:
    # Use pg16 if you have an existing database from PostgreSQL 16
    # PostgreSQL major versions are NOT compatible — you cannot use a pg17
    # image to read data created by pg16 (or vice versa) without a migration.
    image: pgvector/pgvector:pg17
    env_file:
      - stack.env
    environment:
      POSTGRES_USER: admin
      POSTGRES_DB: overseek
      # POSTGRES_PASSWORD comes from stack.env via env_file
      # Do NOT set it here — Docker Compose interpolation doesn't read env_file
      # Ports removed to prevent external access
      # ports:
      #   - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_backups:/backups # Backup volume for migrations
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U admin -d overseek" ]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Elasticsearch — requires version 9.x (matches the @elastic/elasticsearch client)
  # Do NOT downgrade to 8.x without also changing the client library in server/package.json
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.2.4
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms${ES_HEAP_MIN:-256m} -Xmx${ES_HEAP_MAX:-512m}"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    # Ports removed to prevent external access
    # ports:
    #   - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./elasticsearch/config/operator/settings.json:/usr/share/elasticsearch/config/operator/settings.json:ro
    healthcheck:
      test: [ "CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"\\|\"status\":\"yellow\"'" ]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis (Queue & Cache)
  redis:
    image: redis:alpine
    # Ports removed to prevent external access
    # ports:
    #   - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Node API (Fastify + Prisma)
  api:
    build:
      context: .
      dockerfile: server/Dockerfile
      args:
        DATABASE_URL: "postgresql://dummy:dummy@localhost:5432/dummy"
    deploy:
      resources:
        limits:
          memory: 2g
    pull_policy: build
    ports:
      - "3000:3000"
    env_file:
      - stack.env
    environment:
      # DATABASE_URL is auto-constructed in start.sh from POSTGRES_PASSWORD (in stack.env)
      # This avoids Docker Compose interpolation issues with env_file
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: admin
      POSTGRES_DB: overseek
      ELASTICSEARCH_URL: http://elasticsearch:9200
      PORT: 3000
      REDIS_HOST: redis
    volumes:
      - uploads_data:/app/server/uploads
      - geoip_data:/app/server/data
    depends_on:
      postgres:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost:3000/health/live || exit 1" ]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 180s
    extra_hosts:
      - "host.docker.internal:host-gateway" # Allow container to reach host
    networks:
      - default
      - proxy-net
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  web:
    build:
      context: ./client
      dockerfile: Dockerfile
    pull_policy: build
    ports:
      - "5173:80" # External 5173 -> Internal Nginx 80
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost/health || exit 1" ]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - default
      - proxy-net
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
  postgres_backups: # Separate volume for database backups (survives data volume deletion)
  elasticsearch_data:
  redis_data:
  uploads_data:
  geoip_data:


networks:
  proxy-net:
    # For reverse proxy integration (e.g. Nginx Proxy Manager):
    # 1. Create the network on your host: docker network create proxy-net
    # 2. Uncomment the line below so containers join the existing network:
    external: true
